# -*- coding: utf-8 -*-
"""MPT_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eFzRKQBkremoLqxpMN7dTP8AFk7utLUJ
"""

# Cell 0 â€” Installs (Colab only). Skip locally if already installed.
!pip install -q yfinance pandas numpy matplotlib seaborn scikit-learn streamlit dash jupyter-dash

# Cell 1 â€” Imports & style
import warnings; warnings.filterwarnings("ignore")

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (12, 6)

print("âœ… Imports OK.")

# Cell 2 â€” Define universe
tickers = [
    'AAPL','MSFT','GOOG','AMZN','TSLA','NVDA','META','JPM','V','DIS',
    'PEP','KO','CSCO','NFLX','BMY','PFE','WMT','CVX','MCD','XOM',
    'BA','T','INTC','NKE','ADBE','COST','GS','IBM','ORCL','QCOM',
    'UNH','LLY','CRM','GE','HON','LOW','MDLZ','BLK','TMO','UPS',
    'ABT','CAT','DE','BKNG','PYPL','AMD','AMGN','AXP','SBUX','RTX'
]
print(f"ðŸ§º Ticker count: {len(tickers)}")
print("Sample:", tickers[:10])

# Cell 3 â€” Download Adjusted Close prices; inspect shapes & dates
start, end = "2020-01-01", "2024-12-31"
raw = yf.download(tickers, start=start, end=end, auto_adjust=False)

# Keep only Adj Close, align columns to tickers we requested (in case of missing)
data = raw['Adj Close'][[t for t in tickers if t in raw['Adj Close'].columns]]

print("ðŸ“¥ Data shape (dates Ã— tickers):", data.shape)
print("ðŸ“… Date range:", data.index.min().date(), "â†’", data.index.max().date())
print("ðŸ§ª First 3 rows:\n", data.head(3))
missing = set(tickers) - set(data.columns)
print("âš  Missing tickers (if any):", missing if missing else "None")

# Cell 4 â€” Returns, mean (annualized), std (annualized), covariance (annualized)
returns = data.pct_change().dropna()

mean_returns = returns.mean() * 252                # annualized mean
std_returns  = returns.std() * np.sqrt(252)        # annualized std
cov_matrix   = returns.cov() * 252                 # annualized covariance

print("ðŸ“ˆ returns shape:", returns.shape)
print("ðŸ“Š mean_returns (first 5):\n", mean_returns.head())
print("ðŸ“Š std_returns  (first 5):\n", std_returns.head())
print("ðŸ“ cov_matrix shape:", cov_matrix.shape)
print("ðŸ“ cov_matrix sample (5Ã—5):\n", cov_matrix.iloc[:5, :5])

# sanity checks
print("\nðŸ”Ž NaN checks â€”",
      "data:", data.isna().sum().sum(),
      "| returns:", returns.isna().sum().sum(),
      "| mean:", mean_returns.isna().sum(),
      "| cov:", cov_matrix.isna().sum().sum())

# Cell 5 â€” Visualize expected return and risk by stock
ax = mean_returns.sort_values().plot(kind='barh', title="Expected Annual Return by Ticker")
ax.set_xlabel("Annual Return"); ax.grid(True)
plt.show()

ax = std_returns.sort_values().plot(kind='barh', title="Annualized Risk (Std Dev) by Ticker", color='salmon')
ax.set_xlabel("Std Dev"); ax.grid(True)
plt.show()

# Cell 6 â€” Simulate random portfolios (8â€“10 stocks each)
np.random.seed(42)
num_portfolios = 15000
rf = 0.02  # risk-free rate

records = {
    'Return': [], 'Risk': [], 'Sharpe': [], 'Weights': [], 'Stocks': []
}

for i in range(num_portfolios):
    subset_size  = np.random.randint(8, 11)                 # 8â€“10 inclusive
    stock_subset = np.random.choice(mean_returns.index, size=subset_size, replace=False)

    sub_ret = mean_returns[stock_subset].values
    sub_cov = cov_matrix.loc[stock_subset, stock_subset].values

    w = np.random.random(subset_size)
    w = w / w.sum()

    # Portfolio stats
    p_ret = float(np.dot(w, sub_ret))
    p_rsk = float(np.sqrt(np.dot(w.T, np.dot(sub_cov, w))))
    p_shp = (p_ret - rf) / p_rsk if p_rsk > 0 else -np.inf

    records['Return'].append(p_ret)
    records['Risk'].append(p_rsk)
    records['Sharpe'].append(p_shp)
    records['Weights'].append(w)
    records['Stocks'].append(stock_subset)

# Build DataFrame
portfolios = pd.DataFrame(records)
print("ðŸ§® portfolios shape:", portfolios.shape)
print("ðŸ”¹ Head:\n", portfolios.head(3))

# Peek at one random portfolioâ€™s internals
row = portfolios.sample(1, random_state=7).iloc[0]
print("\nðŸ” Sample portfolio (one row):")
print("Stocks:", list(row['Stocks']))
print("Weights (sum=%.4f):" % row['Weights'].sum(), np.round(row['Weights'], 4))
print("Return=%.4f, Risk=%.4f, Sharpe=%.2f" % (row['Return'], row['Risk'], row['Sharpe']))

# Cell 7 â€” Plot efficient frontier & highlight Max Sharpe
plt.figure(figsize=(12,6))
sc = plt.scatter(portfolios['Risk'], portfolios['Return'],
                 c=portfolios['Sharpe'], cmap='viridis', alpha=0.4)
plt.colorbar(sc, label='Sharpe')

max_idx = portfolios['Sharpe'].idxmax()
max_row = portfolios.loc[max_idx]
plt.scatter(max_row['Risk'], max_row['Return'], color='gold', s=200, marker='*', label='Max Sharpe')

plt.xlabel("Risk (Std Dev)")
plt.ylabel("Expected Return")
plt.title("Efficient Frontier (8â€“10 stock portfolios)")
plt.legend()
plt.grid(True)
plt.show()

print("â­ Max Sharpe Portfolio")
print("Return  : %.2f%%" % (100*max_row['Return']))
print("Risk    : %.2f%%" % (100*max_row['Risk']))
print("Sharpe  : %.2f"   % (max_row['Sharpe']))
print("Stocks  :", list(max_row['Stocks']))
print("Weights :", np.round(max_row['Weights'], 4), "| sum=%.4f" % max_row['Weights'].sum())

# Cell 8 â€” Client preference filter and best match
client_min_return = 0.13   # 13%
client_max_risk   = 0.22   # 22%

mask = (portfolios['Return'] >= client_min_return) & (portfolios['Risk'] <= client_max_risk)
client_match = portfolios[mask].copy()

print(f"ðŸŽ¯ Client constraints: Return â‰¥ {client_min_return:.0%}, Risk â‰¤ {client_max_risk:.0%}")
print("âœ… Matching portfolios:", len(client_match))

if not client_match.empty:
    best = client_match.sort_values('Sharpe', ascending=False).iloc[0]
    print("\nðŸ“Œ Best Match (highest Sharpe within constraints)")
    print("Return  : %.2f%%" % (100*best['Return']))
    print("Risk    : %.2f%%" % (100*best['Risk']))
    print("Sharpe  : %.2f"   % best['Sharpe'])
    print("Stocks  :", list(best['Stocks']))
    print("Weights :", np.round(best['Weights'], 4), "| sum=%.4f" % best['Weights'].sum())

    # allocation table (clean view)
    alloc = pd.DataFrame({
        'Stock': best['Stocks'],
        'Weight': np.round(best['Weights'], 4),
        'Ann.Return': np.round(mean_returns[best['Stocks']].values, 4)
    }).sort_values('Weight', ascending=False).reset_index(drop=True)
    print("\nðŸ“‹ Allocation table:")
    display(alloc)
else:
    print("âš  No portfolios matched. Consider relaxing constraints.")

# Cell 9 â€” Overlay client matches and best pick (if any)
plt.figure(figsize=(12,6))
sc = plt.scatter(portfolios['Risk'], portfolios['Return'],
                 c=portfolios['Sharpe'], cmap='viridis', alpha=0.35)
plt.colorbar(sc, label='Sharpe')

if not client_match.empty:
    plt.scatter(client_match['Risk'], client_match['Return'], color='red', s=30, label='Client-Matched')
    best = client_match.sort_values('Sharpe', ascending=False).iloc[0]
    plt.scatter(best['Risk'], best['Return'], color='gold', s=200, marker='*', label='Best Match')

plt.xlabel("Risk (Std Dev)")
plt.ylabel("Expected Return")
plt.title("Efficient Frontier â€” Matches Highlighted")
plt.grid(True)
plt.legend()
plt.show()